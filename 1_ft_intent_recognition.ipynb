{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f9208d-dee4-433d-b9c1-8e52976d118a",
   "metadata": {},
   "source": [
    "# Fine-Tune Intent Recognition Model in LoRA way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9e414f-92f4-4102-abb6-55010cb6e76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07607cd-442d-4080-99e1-3ca92985be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 101)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a3459b-a86d-4acd-8a00-ee7b51d0aac4",
   "metadata": {},
   "source": [
    "### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d071c93-f4e4-44af-90cf-796ef905acef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont have a user account can ya help me open it</td>\n",
       "      <td>Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like to close a user account, where to do it?</td>\n",
       "      <td>Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm trying to find informayion about the current balance of my account</td>\n",
       "      <td>Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dotn wanna keep my fucking account help me close it</td>\n",
       "      <td>Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i got to close a fucking user account how to do it</td>\n",
       "      <td>Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>How do I register to vote?</td>\n",
       "      <td>Nonbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>What are the requirements for a name change?</td>\n",
       "      <td>Nonbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>Where can I get a copy of my birth certificate?</td>\n",
       "      <td>Nonbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>How do I apply for social security benefits?</td>\n",
       "      <td>Nonbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>Can I get an electronic copy of my tax return?</td>\n",
       "      <td>Nonbank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1320 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 instruction  \\\n",
       "0                          i dont have a user account can ya help me open it   \n",
       "1                          I'd like to close a user account, where to do it?   \n",
       "2     I'm trying to find informayion about the current balance of my account   \n",
       "3                      i dotn wanna keep my fucking account help me close it   \n",
       "4                         i got to close a fucking user account how to do it   \n",
       "...                                                                      ...   \n",
       "1315                                              How do I register to vote?   \n",
       "1316                            What are the requirements for a name change?   \n",
       "1317                         Where can I get a copy of my birth certificate?   \n",
       "1318                            How do I apply for social security benefits?   \n",
       "1319                          Can I get an electronic copy of my tax return?   \n",
       "\n",
       "     category  \n",
       "0        Bank  \n",
       "1        Bank  \n",
       "2        Bank  \n",
       "3        Bank  \n",
       "4        Bank  \n",
       "...       ...  \n",
       "1315  Nonbank  \n",
       "1316  Nonbank  \n",
       "1317  Nonbank  \n",
       "1318  Nonbank  \n",
       "1319  Nonbank  \n",
       "\n",
       "[1320 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(\"datasets\",\"generated_inquiries.csv\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ca5b16-bbb3-4077-bc75-ff98512a67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change label to binary\n",
    "data.loc[data['category'] == 'Nonbank', 'category'] = 0\n",
    "data.loc[data['category'] == 'Bank', 'category'] = 1\n",
    "data['category'] = data['category'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac6714a-de85-4a2f-b2a1-a37e9204865d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont have a user account can ya help me open it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like to close a user account, where to do it?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm trying to find informayion about the current balance of my account</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dotn wanna keep my fucking account help me close it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i got to close a fucking user account how to do it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              instruction  \\\n",
       "0                       i dont have a user account can ya help me open it   \n",
       "1                       I'd like to close a user account, where to do it?   \n",
       "2  I'm trying to find informayion about the current balance of my account   \n",
       "3                   i dotn wanna keep my fucking account help me close it   \n",
       "4                      i got to close a fucking user account how to do it   \n",
       "\n",
       "   category  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e52fb86-4d4e-491a-bb69-3959a9b898ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "1    720\n",
       "0    600\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples are balanced\n",
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e668d251-ec65-49f0-839a-f7276cd0c115",
   "metadata": {},
   "source": [
    "### 2. Tokenization with Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ff249a-1ef4-4bd6-bb48-a7ebea288b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PreTrained_Model = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1dc3bf9-3a74-4b5f-9772-2d4470c91594",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PreTrained_Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee576ab-5197-4843-8356-ec874c7d9160",
   "metadata": {},
   "source": [
    "### 3. Prepare Training/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912cf254-a7d2-468d-933b-ff710854a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f86af2e-82ae-4e0f-ba25-788c6fd690f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04158898-f37a-40ba-8262-7e47f0364d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data['instruction'].to_numpy(), data['category'].to_numpy(), test_size=0.2)\n",
    "\n",
    "train_dataset = NewsDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = NewsDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02faff32-6a6e-442a-84f2-2130f74fffcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ad5180-b765-4d8e-af3a-e0033d6bc465",
   "metadata": {},
   "source": [
    "### 4. Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb48916b-5349-4ba6-aa30-ca68ee490708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d562e72-a4d3-4be3-9175-2a6eb2bca4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load the pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained(PreTrained_Model, num_labels=2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Freeze BERT parameters\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca9eb50-8b40-4cf9-b324-4b4326a1b929",
   "metadata": {},
   "source": [
    "### 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9721b9ea-ca36-4f0f-802c-c137e91de352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,  # Define the task type\n",
    "    r=8,  # Rank of low-rank matrices (you can adjust based on your needs)\n",
    "    lora_alpha=16,  # Scaling factor (can be adjusted)\n",
    "    lora_dropout=0.1,  # Dropout for LoRA layers\n",
    "    bias=\"none\"  # Specify whether to include bias terms in the low-rank matrices\n",
    ")\n",
    "\n",
    "# Get the LoRA-enhanced model\n",
    "model_with_lora = get_peft_model(model, lora_config)\n",
    "\n",
    "# Set up training arguments and Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    max_grad_norm=1.0,  # Added gradient clipping\n",
    "    load_best_model_at_end=True,  # Load best model at end of training\n",
    "    metric_for_best_model=\"eval_loss\",  # Use validation loss to select best model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a50d7bad-41d4-4298-835d-1156b5cb3625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_9744\\4287749045.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# Define Trainer for evaluation\n",
    "trainer = Trainer(\n",
    "    model=model_with_lora,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=lambda eval_pred: {\n",
    "        \"accuracy\": accuracy_score(eval_pred.label_ids, eval_pred.predictions.argmax(-1)),\n",
    "        \"f1\": f1_score(eval_pred.label_ids, eval_pred.predictions.argmax(-1), average='binary')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aed11ea6-21ee-4482-a1c4-ab529dca64cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [660/660 00:27, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.708100</td>\n",
       "      <td>0.679211</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.718447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.646800</td>\n",
       "      <td>0.654971</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.734694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.641400</td>\n",
       "      <td>0.621394</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.924138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.624900</td>\n",
       "      <td>0.586556</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.899628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>0.572870</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.887218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=660, training_loss=0.6430802677616928, metrics={'train_runtime': 27.2259, 'train_samples_per_second': 193.933, 'train_steps_per_second': 24.242, 'total_flos': 348508709683200.0, 'train_loss': 0.6430802677616928, 'epoch': 5.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ffba85-851b-408f-b9db-8f04d30aebf4",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b0c5cfd-0459-4beb-ab00-6beb68df8d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_lora.eval()\n",
    "all_predictions = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "673cbe11-7c88-4f97-b958-b62847dba5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model_with_lora(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d06a034-375f-4002-9552-bb268aab5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions, average='binary')\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "class_report = classification_report(all_labels, all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2d8b177-741d-45d1-bb1a-716d2fe7ea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 88.64%\n",
      "Validation F1 Score: 0.89\n",
      "\n",
      "Confusion Matrix:\n",
      "[[116   0]\n",
      " [ 30 118]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.89       116\n",
      "           1       1.00      0.80      0.89       148\n",
      "\n",
      "    accuracy                           0.89       264\n",
      "   macro avg       0.90      0.90      0.89       264\n",
      "weighted avg       0.91      0.89      0.89       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Validation F1 Score: {f1:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad94a9-be67-4634-8a34-16fbc854e7a5",
   "metadata": {},
   "source": [
    "### 6. Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e60e280-92db-4047-bf0d-f9177947681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, texts, tokenizer):\n",
    "    model.eval()\n",
    "    encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12933e1-f51d-4e03-b66c-55e25637140f",
   "metadata": {},
   "source": [
    "#### 6.1 Predict on Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d80b345-c3ec-4cb4-b015-382e8b38f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_list = []\n",
    "\n",
    "for text in train_texts:\n",
    "    pred = predict(model_with_lora, text, tokenizer)\n",
    "    train_pred_list.append(pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3897b96-d014-499b-858f-2b25a8371e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training dataset: 0.9223\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(train_labels, train_pred_list)\n",
    "print(f'Accuracy of training dataset: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27cc3412-770c-4146-9735-b3c820cd5058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of training dataset: 0.92\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(train_labels, train_pred_list, average='binary')\n",
    "print(f\"F1 Score of training dataset: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa95bccc-ed18-4728-a13c-9c1ef566c0e7",
   "metadata": {},
   "source": [
    "#### 6.2 Predict on Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ef0bd56-f505-48c1-bd93-f5fb49202d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_list = []\n",
    "\n",
    "for text in val_texts:\n",
    "    pred = predict(model_with_lora, text, tokenizer)\n",
    "    val_pred_list.append(pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e635c89b-cb50-44ab-ae67-be8544a13d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training dataset: 0.8864\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(val_labels, val_pred_list)\n",
    "print(f'Accuracy of training dataset: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71427be2-13bf-4fcc-83bc-67aee52ee174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of training dataset: 0.89\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(val_labels, val_pred_list, average='binary')\n",
    "print(f\"F1 Score of training dataset: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d125ef9-a6dd-4a00-8369-0f8c4647ad6a",
   "metadata": {},
   "source": [
    "#### 6.3 Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e01682d3-f7ff-4431-a2d8-018652124797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model_with_lora, \"may i book a hotel number?\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d2a85cb-9403-456e-9222-625f7afc64aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model_with_lora, \"i dotn wanna keep my fucking account help me close it\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "daec23c7-39e3-4a90-96cf-c11161fd33fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1], device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model_with_lora, \"I'd like information transaction details\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a2836-5770-4aa6-8365-9fe86635aade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
