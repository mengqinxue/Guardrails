{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f9208d-dee4-433d-b9c1-8e52976d118a",
   "metadata": {},
   "source": [
    "# Fine-Tune Intent Recognition Model in LoRA way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9e414f-92f4-4102-abb6-55010cb6e76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shutil import unpack_archive\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07607cd-442d-4080-99e1-3ca92985be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 101)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a3459b-a86d-4acd-8a00-ee7b51d0aac4",
   "metadata": {},
   "source": [
    "### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d071c93-f4e4-44af-90cf-796ef905acef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont have a user account can ya help me open it</td>\n",
       "      <td>Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like to close a user account, where to do it?</td>\n",
       "      <td>Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm trying to find informayion about the current balance of my account</td>\n",
       "      <td>Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dotn wanna keep my fucking account help me close it</td>\n",
       "      <td>Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i got to close a fucking user account how to do it</td>\n",
       "      <td>Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15195</th>\n",
       "      <td>I have to book a hotel Nonbank, how can I do it?</td>\n",
       "      <td>Nonbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15196</th>\n",
       "      <td>I have to download a file Nonbank, how can I do it?</td>\n",
       "      <td>Nonbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15197</th>\n",
       "      <td>I have to file my taxes Nonbank, how can I do it?</td>\n",
       "      <td>Nonbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15198</th>\n",
       "      <td>I have to book a hotel Nonbank, how can I do it?</td>\n",
       "      <td>Nonbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15199</th>\n",
       "      <td>I have to file my taxes Nonbank, how can I do it?</td>\n",
       "      <td>Nonbank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  instruction  \\\n",
       "0                           i dont have a user account can ya help me open it   \n",
       "1                           I'd like to close a user account, where to do it?   \n",
       "2      I'm trying to find informayion about the current balance of my account   \n",
       "3                       i dotn wanna keep my fucking account help me close it   \n",
       "4                          i got to close a fucking user account how to do it   \n",
       "...                                                                       ...   \n",
       "15195                        I have to book a hotel Nonbank, how can I do it?   \n",
       "15196                     I have to download a file Nonbank, how can I do it?   \n",
       "15197                       I have to file my taxes Nonbank, how can I do it?   \n",
       "15198                        I have to book a hotel Nonbank, how can I do it?   \n",
       "15199                       I have to file my taxes Nonbank, how can I do it?   \n",
       "\n",
       "      category  \n",
       "0         Bank  \n",
       "1         Bank  \n",
       "2         Bank  \n",
       "3         Bank  \n",
       "4         Bank  \n",
       "...        ...  \n",
       "15195  Nonbank  \n",
       "15196  Nonbank  \n",
       "15197  Nonbank  \n",
       "15198  Nonbank  \n",
       "15199  Nonbank  \n",
       "\n",
       "[15200 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(\"datasets\",\"generated_inquiries.csv\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ca5b16-bbb3-4077-bc75-ff98512a67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change label to binary\n",
    "data.loc[data['category'] == 'Nonbank', 'category'] = 0\n",
    "data.loc[data['category'] == 'Bank', 'category'] = 1\n",
    "data['category'] = data['category'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac6714a-de85-4a2f-b2a1-a37e9204865d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont have a user account can ya help me open it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like to close a user account, where to do it?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm trying to find informayion about the current balance of my account</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dotn wanna keep my fucking account help me close it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i got to close a fucking user account how to do it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              instruction  \\\n",
       "0                       i dont have a user account can ya help me open it   \n",
       "1                       I'd like to close a user account, where to do it?   \n",
       "2  I'm trying to find informayion about the current balance of my account   \n",
       "3                   i dotn wanna keep my fucking account help me close it   \n",
       "4                      i got to close a fucking user account how to do it   \n",
       "\n",
       "   category  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e52fb86-4d4e-491a-bb69-3959a9b898ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "0    8000\n",
       "1    7200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples are balanced\n",
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e668d251-ec65-49f0-839a-f7276cd0c115",
   "metadata": {},
   "source": [
    "### 2. Tokenization with Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ff249a-1ef4-4bd6-bb48-a7ebea288b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PreTrained_Model = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1dc3bf9-3a74-4b5f-9772-2d4470c91594",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PreTrained_Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee576ab-5197-4843-8356-ec874c7d9160",
   "metadata": {},
   "source": [
    "### 3. Prepare Training/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912cf254-a7d2-468d-933b-ff710854a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f86af2e-82ae-4e0f-ba25-788c6fd690f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04158898-f37a-40ba-8262-7e47f0364d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data['instruction'].to_numpy(), data['category'].to_numpy(), test_size=0.2)\n",
    "\n",
    "train_dataset = NewsDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_dataset = NewsDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02faff32-6a6e-442a-84f2-2130f74fffcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ad5180-b765-4d8e-af3a-e0033d6bc465",
   "metadata": {},
   "source": [
    "### 4. Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb48916b-5349-4ba6-aa30-ca68ee490708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d562e72-a4d3-4be3-9175-2a6eb2bca4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load the pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained(PreTrained_Model, num_labels=2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Freeze BERT parameters\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca9eb50-8b40-4cf9-b324-4b4326a1b929",
   "metadata": {},
   "source": [
    "### 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9721b9ea-ca36-4f0f-802c-c137e91de352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,  # Define the task type\n",
    "    r=8,  # Rank of low-rank matrices (you can adjust based on your needs)\n",
    "    lora_alpha=16,  # Scaling factor (can be adjusted)\n",
    "    lora_dropout=0.1,  # Dropout for LoRA layers\n",
    "    bias=\"none\"  # Specify whether to include bias terms in the low-rank matrices\n",
    ")\n",
    "\n",
    "# Get the LoRA-enhanced model\n",
    "model_with_lora = get_peft_model(model, lora_config)\n",
    "\n",
    "# Set up training arguments and Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a50d7bad-41d4-4298-835d-1156b5cb3625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_43156\\1510435588.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7600' max='7600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7600/7600 12:28, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.005439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D109EBD150>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 3a9b2ced-c915-4480-9c9e-a37f4baef136)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D119F57CA0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: f109ef75-a947-4294-bfbd-9ee864644e83)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D10A13D030>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: b5104ca1-3921-4fbd-9c41-e06c21845a8a)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D0F451E860>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 5de1d706-538b-4374-aa42-e2fa17e0fadb)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D10A13D1E0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 5ee08898-b327-4bf7-a060-2f74e7a6909c)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D10A162530>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 7c10c403-f4a6-47b5-85b5-09e9dd4eb835)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D10A162530>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 81e6983d-40b9-4ee4-b0ea-c7763964af51)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D10A16F250>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: deb02b15-bae9-4ac5-b29e-a6abd61700b3)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D10A000730>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 999b4330-474e-4311-bd8e-1b7c05688df3)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D10A13D1E0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 05cf052f-9681-441d-8e43-2e863239e3ac)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D109F0D7B0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: c3c1fe80-5760-40ca-b91b-b07e781b9bad)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D109F0D660>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 6c1a01a8-8605-4d70-9b26-98b711c190e0)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D10A160B80>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 9b2b6fe6-24d5-4cda-a0c4-d6f618648226)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D0F451C580>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: dbb89ba9-3dff-4307-8f0d-bf11e04109dc)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D0F43A4A90>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 93db7eff-d89f-43d5-8cb9-8f374d6c7468)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\other.py:1094: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001D10A16FFA0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: d8b5f41e-4ab6-4811-8a64-f0fc986eb5e7)') - silently ignoring the lookup for the file config.json in bert-base-uncased.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\.conda\\envs\\py310torch\\lib\\site-packages\\peft\\utils\\save_and_load.py:227: UserWarning: Could not find a config file in bert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7600, training_loss=0.01629712776536747, metrics={'train_runtime': 749.0564, 'train_samples_per_second': 162.338, 'train_steps_per_second': 10.146, 'total_flos': 8026261192704000.0, 'train_loss': 0.01629712776536747, 'epoch': 10.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Trainer for evaluation\n",
    "trainer = Trainer(\n",
    "    model=model_with_lora,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ffba85-851b-408f-b9db-8f04d30aebf4",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c13a2f43-ea31-4832-98e2-b04919f4f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d33ce01-b680-4205-b272-a29afe8aeb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_dataloader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "\n",
    "    accuracy = total_correct / total_count\n",
    "    f1 = f1_score(all_labels, all_predictions, average='binary')  # 'binary' for 2-class classification\n",
    "\n",
    "    print(f\"Validation accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Validation F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b0c5cfd-0459-4beb-ab00-6beb68df8d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_correct = 0\n",
    "total_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "673cbe11-7c88-4f97-b958-b62847dba5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        # attention_mask = batch['attention_ma sk'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "        total_correct += (predictions == labels).sum().item()\n",
    "        total_count += labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d06a034-375f-4002-9552-bb268aab5ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 63.26%\n"
     ]
    }
   ],
   "source": [
    "accuracy = total_correct / total_count\n",
    "print(f\"Validation accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad94a9-be67-4634-8a34-16fbc854e7a5",
   "metadata": {},
   "source": [
    "### 6. Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e60e280-92db-4047-bf0d-f9177947681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, texts, tokenizer):\n",
    "    model.eval()\n",
    "    encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d80b345-c3ec-4cb4-b015-382e8b38f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_list = []\n",
    "\n",
    "for text in train_texts:\n",
    "    pred = predict(model_with_lora, text, tokenizer)\n",
    "    train_pred_list.append(predictions.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3897b96-d014-499b-858f-2b25a8371e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training dataset: 0.5260\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(train_labels, train_pred_list)\n",
    "print(f'Accuracy of training dataset: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eeaec4fe-919f-4322-816d-8d76f31504cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of training dataset: 0.00\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(train_labels, train_pred_list, average='binary')  # 'binary' for 2-class classification\n",
    "print(f\"F1 Score of training dataset: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27cc3412-770c-4146-9735-b3c820cd5058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0bd56-f505-48c1-bd93-f5fb49202d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
